{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Import Births and Deaths Places"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# %load /home/gaetan/Desktop/geovpylib/templates/heading.py\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Common imports\n","import os\n","import pandas as pd, numpy as np\n","import datetime\n","#import time\n","#import json\n","#import requests\n","#import duckdb\n","#import plotly.express as px\n","# from multiprocessing import Pool\n","\n","# Geovpylib library\n","import geovpylib.analysis as a\n","import geovpylib.database as db\n","import geovpylib.decorators as d\n","import geovpylib.importer as i\n","import geovpylib.magics\n","import geovpylib.pks as pks\n","import geovpylib.queries as q\n","import geovpylib.record_linkage as rl\n","import geovpylib.sparql as sparql\n","import geovpylib.utils as u\n","eta = u.Eta()\n","\n","# Connect to Geovistory database read mode\n","# db.connect_geovistory('prod')\n","\n","# Connect to Geovistory database for insert\n","env = 'prod' # Database to query: \"prod\", \"stag\", \"dev\", \"local\"\n","pk_project = pks.projects.switzerland_and_beyond # The project to query/insert: integer\n","execute = True # Boolean to prevent to execute directly into databases\n","metadata_str = 'import-geo-places' # kebab-lower-case or snake-lower-case. \n","import_manner = 'one-shot' # 'one-shot' or 'batch'\n","\n","# Connect to other database\n","# db_url_env_var_name = 'YELLOW_' # Name of an environment variable holding the Postgres database URL\n","# execute = False # Boolean to prevent to execute directly into databases\n","# db.connect_external(os.getenv(db_url_env_var_name), execute=False)\n","\n","# Connect to a SPARQL endpoint\n","# sparql.connect_external('url')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Get infos from wikidata"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[">> External SPARQL URL set to <https://query.wikidata.org/sparql>\n"]}],"source":["sparql.connect_external('https://query.wikidata.org/sparql')\n","\n","births = sparql.query(\"\"\"\n","    SELECT ?uri_wikidata_person ?hls_id ?uri_wikidata_place ?uri_wikidata_placeLabel ?placeCoordinates ?placeDescription ?place_classLabel\n","    WHERE {\n","        ?uri_wikidata_person wdt:P31 wd:Q5 .\n","        ?uri_wikidata_person wdt:P902 ?hls_id .\n","        ?uri_wikidata_person wdt:P19 ?uri_wikidata_place .\n","        ?uri_wikidata_place wdt:P31 ?place_class .\n","        optional { ?uri_wikidata_place wdt:P625 ?placeCoordinates .}\n","        SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n","      \n","        SERVICE wikibase:label { \n","            bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" . \n","            ?uri_wikidata_place schema:description ?placeDescription .\n","        }\n","    }\n","\"\"\")\n","u.write_df(births, './births-wd.csv')\n","\n","deaths = sparql.query(\"\"\"\n","    SELECT ?uri_wikidata_person ?hls_id ?uri_wikidata_place ?uri_wikidata_placeLabel ?placeCoordinates ?placeDescription ?place_classLabel\n","    WHERE {\n","        ?uri_wikidata_person wdt:P31 wd:Q5 .\n","        ?uri_wikidata_person wdt:P902 ?hls_id .\n","        ?uri_wikidata_person wdt:P20 ?uri_wikidata_place .\n","        ?uri_wikidata_place wdt:P31 ?place_class .\n","        optional { ?uri_wikidata_place wdt:P625 ?placeCoordinates .}\n","        SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". }\n","      \n","        SERVICE wikibase:label { \n","            bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\" . \n","            ?uri_wikidata_place schema:description ?placeDescription .\n","        }\n","    }\n","\"\"\")\n","u.write_df(births, './deaths-wd.csv')\n","\n","# 26s\n","\n","\n","births = u.read_df('./births-wd.csv')\n","births['hls_id'] = births['hls_id'].astype(pd.Int64Dtype())\n","\n","deaths = u.read_df('./deaths-wd.csv')\n","deaths['hls_id'] = deaths['hls_id'].astype(pd.Int64Dtype())\n","\n","# print(births.shape)\n","# print(deaths.shape)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape:  (5959, 7) - extract:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>definition</th>\n","      <th>lat</th>\n","      <th>lng</th>\n","      <th>uri</th>\n","      <th>place_classLabel</th>\n","      <th>kind</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>27795</th>\n","      <td>Kaliningrad</td>\n","      <td>Russian Baltic city between Poland and Lithuania</td>\n","      <td>54.716667</td>\n","      <td>20.5</td>\n","      <td>http://www.wikidata.org/entity/Q1829</td>\n","      <td>big city</td>\n","      <td>Settlement</td>\n","    </tr>\n","    <tr>\n","      <th>6183</th>\n","      <td>Untervaz</td>\n","      <td>municipality in Switzerland</td>\n","      <td>46.9275</td>\n","      <td>9.535</td>\n","      <td>http://www.wikidata.org/entity/Q69095</td>\n","      <td>municipality of Switzerland</td>\n","      <td>Settlement</td>\n","    </tr>\n","    <tr>\n","      <th>28214</th>\n","      <td>Frankfurt (Oder)</td>\n","      <td>city in Brandenburg, Germany</td>\n","      <td>52.342083</td>\n","      <td>14.551667</td>\n","      <td>http://www.wikidata.org/entity/Q4024</td>\n","      <td>border town</td>\n","      <td>Settlement</td>\n","    </tr>\n","    <tr>\n","      <th>38033</th>\n","      <td>Schwabach</td>\n","      <td>town in Bavaria, Germany</td>\n","      <td>49.329167</td>\n","      <td>11.020833</td>\n","      <td>http://www.wikidata.org/entity/Q14889</td>\n","      <td>urban district of Bavaria</td>\n","      <td>Settlement</td>\n","    </tr>\n","    <tr>\n","      <th>273</th>\n","      <td>Näfels</td>\n","      <td>village and former municipality in Glarus Nord...</td>\n","      <td>47.098889</td>\n","      <td>9.062778</td>\n","      <td>http://www.wikidata.org/entity/Q182806</td>\n","      <td>village</td>\n","      <td>Settlement</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                   name                                         definition  \\\n","27795       Kaliningrad   Russian Baltic city between Poland and Lithuania   \n","6183           Untervaz                        municipality in Switzerland   \n","28214  Frankfurt (Oder)                       city in Brandenburg, Germany   \n","38033         Schwabach                           town in Bavaria, Germany   \n","273              Näfels  village and former municipality in Glarus Nord...   \n","\n","             lat        lng                                     uri  \\\n","27795  54.716667       20.5    http://www.wikidata.org/entity/Q1829   \n","6183     46.9275      9.535   http://www.wikidata.org/entity/Q69095   \n","28214  52.342083  14.551667    http://www.wikidata.org/entity/Q4024   \n","38033  49.329167  11.020833   http://www.wikidata.org/entity/Q14889   \n","273    47.098889   9.062778  http://www.wikidata.org/entity/Q182806   \n","\n","                  place_classLabel        kind  \n","27795                     big city  Settlement  \n","6183   municipality of Switzerland  Settlement  \n","28214                  border town  Settlement  \n","38033    urban district of Bavaria  Settlement  \n","273                        village  Settlement  "]},"metadata":{},"output_type":"display_data"}],"source":["wd_places = pd.concat([\n","    births[['uri_wikidata_place', 'placeCoordinates', 'placeDescription', 'uri_wikidata_placeLabel', 'place_classLabel']].copy(),\n","    deaths[['uri_wikidata_place', 'placeCoordinates', 'placeDescription', 'uri_wikidata_placeLabel', 'place_classLabel']].copy()\n","]).drop_duplicates()\n","wd_places.rename(columns={'uri_wikidata_place':'uri', 'placeDescription':'definition', 'uri_wikidata_placeLabel':'name'}, inplace=True)\n","wd_places['lat'] = [float(coord.split(' ')[1].replace(')', '')) if pd.notna(coord) else pd.NA for coord in wd_places['placeCoordinates']]\n","wd_places['lng'] = [float(coord.split(' ')[0].replace('Point(', '')) if pd.notna(coord) else pd.NA for coord in wd_places['placeCoordinates']]\n","\n","def parse_kind(row):\n","\n","    classLabel = row['place_classLabel']\n","\n","    if 'settlement' in classLabel: return 'Settlement'\n","    if 'village' in classLabel: return 'Settlement'\n","    if 'city' in classLabel: return 'Settlement'\n","    if 'City' in classLabel: return 'Settlement'\n","    if 'municipality' in classLabel: return 'Settlement'\n","    if 'capital' in classLabel: return 'Settlement'\n","    if 'town' in classLabel: return 'Settlement'\n","    if 'commune' in classLabel: return 'Settlement'\n","    if 'populated place' in classLabel: return 'Settlement'\n","    if 'locality' in classLabel: return 'Settlement'\n","    if 'hamlet' in classLabel: return 'Settlement'\n","    if 'Ortschaft' in classLabel: return 'Settlement'\n","    if 'polis' in classLabel: return 'Settlement'\n","    if 'principality' in classLabel: return 'Settlement'\n","\n","    if 'administrative division' in classLabel: return 'Legal territory'\n","    if 'canton' in classLabel: return 'Legal territory'\n","    if 'state' in classLabel: return 'Legal territory'\n","    if 'district' in classLabel: return 'Legal territory'\n","    if 'Ortsteil' in classLabel: return 'Legal territory'\n","    if 'Ortsteil' in classLabel: return 'Legal territory'\n","    if 'quarter' in classLabel: return 'Legal territory'\n","    if 'country' in classLabel: return 'Legal territory'\n","    if 'duchy' in classLabel: return 'Legal territory'\n","    if 'municipal arrondissement' in classLabel: return 'Legal territory'\n","    if 'uyezd' in classLabel: return 'Legal territory'\n","    if 'civil parish' in classLabel: return 'Legal territory'\n","    if 'colonial power' in classLabel: return 'Legal territory'\n","    if 'colony' in classLabel: return 'Legal territory'\n","    if 'countship' in classLabel: return 'Legal territory'\n","    if 'department' in classLabel: return 'Legal territory'\n","    if 'Ortsbezirk' in classLabel: return 'Legal territory'\n","    if 'Stadtbezirk' in classLabel: return 'Legal territory'\n","    if 'ceremonial county ' in classLabel: return 'Legal territory'\n","    if 'municipal part' in classLabel: return 'Legal territory'\n","    if 'province' in classLabel: return 'Legal territory'\n","    if 'republic' in classLabel: return 'Legal territory'\n","    if 'county' in classLabel: return 'Legal territory'\n","    if 'territorial entity' in classLabel: return 'Legal territory'\n","    if 'parish' in classLabel: return 'Legal territory'\n","    if 'Territory' in classLabel: return 'Legal territory'\n","    if 'kingdoms' in classLabel: return 'Legal territory'\n","    if 'realm' in classLabel: return 'Legal territory'\n","    if 'federative unit of Brazil' in classLabel: return 'Legal territory'\n","    if 'former arrondissement of Paris' in classLabel: return 'Legal territory'\n","    if 'governorate' in classLabel: return 'Legal territory'\n","    if 'nation' in classLabel: return 'Legal territory'\n","    if 'colonia' in classLabel: return 'Legal territory'\n","\n","    if 'château' in classLabel: return 'Infrastructure'\n","    if 'castle' in classLabel: return 'Infrastructure'\n","    if 'architectural' in classLabel: return 'Infrastructure'\n","    if 'museum' in classLabel: return 'Infrastructure'\n","    if 'dog breed' in classLabel: return 'Infrastructure'\n","    if 'building' in classLabel: return 'Infrastructure'\n","    if 'rocca' in classLabel: return 'Infrastructure'\n","    if 'abbey' in classLabel: return 'Infrastructure'\n","    if 'garden' in classLabel: return 'Infrastructure'\n","    if 'winery' in classLabel: return 'Infrastructure'\n","    if 'house' in classLabel: return 'Infrastructure'\n","    if 'institution' in classLabel: return 'Infrastructure'\n","    if 'cultural property' in classLabel: return 'Infrastructure'\n","    if 'local council of Malta' in classLabel: return 'Infrastructure'\n","    if 'presidential system' in classLabel: return 'Infrastructure'\n","    if 'presidential system' in classLabel: return 'Infrastructure'\n","\n","    if 'quartier' in classLabel: return 'Section'\n","    if 'neighborhood' in classLabel: return 'Section'\n","    if 'frazione' in classLabel: return 'Section'\n","    if 'street' in classLabel: return 'Section'\n","\n","    if 'region' in classLabel: return 'Region'\n","    if 'Region' in classLabel: return 'Region'\n","    if 'area' in classLabel: return 'Region'\n","    if 'community' in classLabel: return 'Region'\n","    if 'ancient civilization' in classLabel: return 'Region'\n","    if 'campagne' in classLabel: return 'Region'\n","    if 'historic site' in classLabel: return 'Region'\n","    if 'campagne' in classLabel: return 'Region'\n","    if 'electoral unit' in classLabel: return 'Region'\n","    if 'geographic location' in classLabel: return 'Region'\n","    if 'ruins' in classLabel: return 'Region'\n","\n","    if 'island' in classLabel: return 'Natural element'\n","    if 'hill' in classLabel: return 'Natural element'\n","    if 'mountain' in classLabel: return 'Natural element'\n","    if 'valley' in classLabel: return 'Natural element'\n","\n","\n","    # Manual kind assignings\n","    if row['name'] == 'Altona': return 'Settlement'\n","    if row['name'] == 'Elberfeld': return 'Settlement'\n","    if row['name'] == 'Rauden': return 'Settlement'\n","    if row['name'] == 'Shanghai French Concession': return 'Infrastructure'\n","    if row['name'] == 'Val Bregaglia': return 'Natural element'\n","    if row['name'] == 'Podgórze': return 'Settlement'\n","    if row['name'] == 'Auvergne': return 'Region'\n","    if row['name'] == 'Samiano': return 'Settlement'\n","    if row['name'] == 'United States of America': return 'Legal territory'\n","    if row['name'] == 'Val Fex': return 'Natural element'\n","    if row['name'] == 'Goddelau': return 'Settlement'\n","    if row['name'] == 'Weilheim': return 'Settlement'\n","    if row['name'] == 'Sonnborn': return 'Settlement'\n","    if row['name'] == 'Parish of St Gertrud of Germany': return 'Legal territory'\n","\n","\n","\n","    return pd.NA\n","\n","wd_places['kind'] = [parse_kind(row) for i, row in wd_places.iterrows()]\n","\n","# For each place if it has at least one Settlement kind, we take it as a Settlement\n","for i, row in wd_places.iterrows():\n","    kinds = wd_places[wd_places['uri'] == row['uri']]['kind'].dropna().tolist()\n","    if 'Settlement' in kinds: wd_places.at[i, 'kind'] = 'Settlement'\n","    \n","wd_places = wd_places[['name', 'definition', 'lat', 'lng', 'uri', 'place_classLabel', 'kind']].drop_duplicates()\n","\n","\n","a.infos(wd_places, random=True)\n","\n","# Left to do\n","if len(a.group_by_count(wd_places[pd.isna(wd_places['kind'])], 'place_classLabel')) != 0:\n","    raise Exception('There is places from wikidata with missing Kinds')"]},{"cell_type":"markdown","metadata":{},"source":["# Get GV Geographical places"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[DB] Connecting to PRODUCTION Database ... Connected!\n"]}],"source":["db.connect_geovistory(env, pk_project, execute)\n","db.set_metadata({'import-id': datetime.datetime.today().strftime('%Y%m%d') + '-' + metadata_str})\n","db.set_insert_manner(import_manner)"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape:  (135364, 10) - extract:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pk_geoplace</th>\n","      <th>kind</th>\n","      <th>to_add_kind</th>\n","      <th>name</th>\n","      <th>to_add_name</th>\n","      <th>lat</th>\n","      <th>lng</th>\n","      <th>to_add_coord</th>\n","      <th>uri</th>\n","      <th>to_add_uri</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>25458</td>\n","      <td>Settlement</td>\n","      <td>[739271]</td>\n","      <td>Limburg</td>\n","      <td>[25465, 25460, 25463]</td>\n","      <td>50.398601</td>\n","      <td>8.079578</td>\n","      <td>[149729.0, 149727.0, 149730.0]</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>25458</td>\n","      <td>Settlement</td>\n","      <td>[739271]</td>\n","      <td>Leimburg</td>\n","      <td>[985255, 985249, 985254]</td>\n","      <td>50.398601</td>\n","      <td>8.079578</td>\n","      <td>[149729.0, 149727.0, 149730.0]</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>25485</td>\n","      <td>Settlement</td>\n","      <td>[739272]</td>\n","      <td>Kyburg</td>\n","      <td>[25492, 25487, 25490]</td>\n","      <td>7.438637</td>\n","      <td>46.951081</td>\n","      <td>[300508.0, 300506.0, 300509.0]</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>25485</td>\n","      <td>Settlement</td>\n","      <td>[739272]</td>\n","      <td>Kyburg</td>\n","      <td>[25492, 25487, 25490]</td>\n","      <td>47.458349</td>\n","      <td>8.743733</td>\n","      <td>[300508.0, 300506.0, 300523.0]</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>25485</td>\n","      <td>Settlement</td>\n","      <td>[739272]</td>\n","      <td>Kyburg</td>\n","      <td>[25492, 25487, 25490]</td>\n","      <td>39.611051</td>\n","      <td>52.512393</td>\n","      <td>[300508.0, 300506.0, 300519.0]</td>\n","      <td>&lt;NA&gt;</td>\n","      <td>&lt;NA&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   pk_geoplace        kind to_add_kind      name               to_add_name  \\\n","0        25458  Settlement    [739271]   Limburg     [25465, 25460, 25463]   \n","1        25458  Settlement    [739271]  Leimburg  [985255, 985249, 985254]   \n","2        25485  Settlement    [739272]    Kyburg     [25492, 25487, 25490]   \n","3        25485  Settlement    [739272]    Kyburg     [25492, 25487, 25490]   \n","4        25485  Settlement    [739272]    Kyburg     [25492, 25487, 25490]   \n","\n","         lat        lng                    to_add_coord   uri to_add_uri  \n","0  50.398601   8.079578  [149729.0, 149727.0, 149730.0]  <NA>       <NA>  \n","1  50.398601   8.079578  [149729.0, 149727.0, 149730.0]  <NA>       <NA>  \n","2   7.438637  46.951081  [300508.0, 300506.0, 300509.0]  <NA>       <NA>  \n","3  47.458349   8.743733  [300508.0, 300506.0, 300523.0]  <NA>       <NA>  \n","4  39.611051  52.512393  [300508.0, 300506.0, 300519.0]  <NA>       <NA>  "]},"metadata":{},"output_type":"display_data"}],"source":["gv_places = db.query(f\"\"\"\n","    select distinct\n","        r0.pk_entity as pk_geoplace\n","    from information.resource r0\n","    inner join projects.info_proj_rel ipr0 on ipr0.fk_entity = r0.pk_entity and ipr0.is_in_project = true\n","    where r0.fk_class = {pks.classes.geoPlace}     \n","\"\"\")\n","\n","gv_kind = db.query(f\"\"\"\n","    select distinct\n","        r0.pk_entity as pk_geoplace,\n","        s1.fk_object_info as pk_kind,\n","        s1.pk_entity as pk_stmt_haskind\n","    from information.resource r0\n","    inner join information.statement s1 on s1.fk_subject_info = r0.pk_entity and s1.fk_property = {pks.properties.geoPlace_hasKind_geoPlaceKind}\n","    where r0.fk_class = {pks.classes.geoPlace}     \n","\"\"\")\n","gv_kind['kind'] = [pks.entities.get_kind_label(pk_kind) for pk_kind in gv_kind['pk_kind']]\n","gv_kind['to_add_kind'] = [[row['pk_stmt_haskind']] for i, row in gv_kind.iterrows()]\n","gv_kind.drop(columns=['pk_kind', 'pk_stmt_haskind'], inplace=True)\n","\n","\n","gv_places_name = db.query(f\"\"\"\n","    select distinct\n","        r0.pk_entity as pk_geoplace,\n","        a3.string as name,\n","        s1.pk_entity as pk_stmt_isaialof,\n","        s1.fk_subject_info as pk_aial,\n","        s2.pk_entity as pk_stmt_referstoname\n","    from information.resource r0\n","    inner join information.statement s1 on s1.fk_object_info = r0.pk_entity and s1.fk_property = {pks.properties.aial_isAppelationForLanguageOf_entity}\n","    inner join information.statement s2 on s2.fk_subject_info = s1.fk_subject_info and s2.fk_property = {pks.properties.aial_refersToName_appellation}\n","    inner join information.appellation a3 on a3.pk_entity = s2.fk_object_info\n","    where r0.fk_class = {pks.classes.geoPlace}     \n","\"\"\")\n","gv_places_name['to_add_name'] = [[row['pk_stmt_isaialof'], row['pk_aial'], row['pk_stmt_referstoname']] for i, row in gv_places_name.iterrows()]\n","gv_places_name.drop(columns=['pk_stmt_isaialof', 'pk_aial', 'pk_stmt_referstoname'], inplace=True)\n","\n","\n","gv_places_coordinates = db.query(f\"\"\"\n","    select distinct\n","        r0.pk_entity as pk_geoplace,\n","        st_y(p5.geo_point::geometry) as lat, st_x(p5.geo_point::geometry) as lng,\n","        s3.pk_entity as pk_stmt_waspresenceof,\n","        s3.fk_subject_info as pk_presence,\n","        s4.pk_entity as pk_stmt_wasat      \n","    from information.resource r0\n","    inner join information.statement s3 on s3.fk_object_info = r0.pk_entity and s3.fk_property = {pks.properties.presence_wasPresenceOf_spacetimeVolume}\n","    inner join information.statement s4 on s4.fk_subject_info = s3.fk_subject_info and s4.fk_property = {pks.properties.presence_wasAt_place}\n","    inner join information.place p5 on p5.pk_entity = s4.fk_object_info \n","    where r0.fk_class = {pks.classes.geoPlace}                     \n","\"\"\")\n","gv_places_coordinates['to_add_coord'] = [[row['pk_stmt_waspresenceof'], row['pk_presence'], row['pk_stmt_wasat']] for i, row in gv_places_coordinates.iterrows()]\n","gv_places_coordinates.drop(columns=['pk_stmt_waspresenceof', 'pk_presence', 'pk_stmt_wasat'], inplace=True)\n","\n","\n","gv_places_uris = db.query(f\"\"\"\n","    select distinct\n","        r0.pk_entity as pk_geoplace,\n","        a8.string as uri,\n","        s6.pk_entity as pk_stmt_sameas,\n","        s6.fk_object_info as pk_uri,\n","        s7.pk_entity as pk_stmt_hasvalue      \n","    from information.resource r0\n","    inner join information.statement s6 on s6.fk_subject_info = r0.pk_entity and s6.fk_property = {pks.properties.entity_sameAsURI_URI}\n","    inner join information.statement s7 on s7.fk_subject_info = s6.fk_object_info and s7.fk_property = {pks.properties.appe_hasValue_string}\n","    inner join information.appellation a8 on a8.pk_entity = s7.fk_object_info\n","    where r0.fk_class = {pks.classes.geoPlace}                      \n","\"\"\")\n","gv_places_uris['to_add_uri'] = [[row['pk_stmt_sameas'], row['pk_uri'], row['pk_stmt_hasvalue']] for i, row in gv_places_uris.iterrows()]\n","gv_places_uris.drop(columns=['pk_stmt_sameas', 'pk_uri', 'pk_stmt_hasvalue'], inplace=True)\n","\n","\n","# We only take those who have a kind! ==> inner join\n","gv_places = gv_places \\\n","                .merge(gv_kind, how='inner', on='pk_geoplace') \\\n","                .merge(gv_places_name, how='left', on='pk_geoplace') \\\n","                .merge(gv_places_coordinates, how='left', on='pk_geoplace') \\\n","                .merge(gv_places_uris, how='left', on='pk_geoplace')\n","\n","u.write_df(gv_places, './gv-places.csv')\n","\n","gv_places = u.read_df('./gv-places.csv')\n","gv_places['pk_geoplace'] = gv_places['pk_geoplace'].astype(pd.Int64Dtype())\n","gv_places['lat'] = gv_places['lat'].astype(pd.Float64Dtype())\n","gv_places['lng'] = gv_places['lng'].astype(pd.Float64Dtype())\n","\n","a.infos(gv_places)"]},{"cell_type":"markdown","metadata":{},"source":["# Place Record linkage"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['Settlement', 'Legal territory', 'Region', 'Natural element', 'Infrastructure', 'Section']\n","['Settlement', <NA>, 'Legal territory', 'Region', 'Section', 'Address', 'Natural element', 'Infrastructure']\n"]}],"source":["# Kind manual verifications\n","print(wd_places['kind'].unique().tolist())\n","print(gv_places['kind'].unique().tolist())"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Finding existing places is done - Elapsed: [00h18m16s]                                                                       \n","Shape:  (910, 2) - extract:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>wd_uri</th>\n","      <th>pk_gv</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>http://www.wikidata.org/entity/Q70</td>\n","      <td>80681</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>http://www.wikidata.org/entity/Q72</td>\n","      <td>25494</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>http://www.wikidata.org/entity/Q78</td>\n","      <td>80974</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>http://www.wikidata.org/entity/Q1034</td>\n","      <td>205648</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>http://www.wikidata.org/entity/Q1309</td>\n","      <td>11134943</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                  wd_uri     pk_gv\n","0     http://www.wikidata.org/entity/Q70     80681\n","9     http://www.wikidata.org/entity/Q72     25494\n","13    http://www.wikidata.org/entity/Q78     80974\n","19  http://www.wikidata.org/entity/Q1034    205648\n","21  http://www.wikidata.org/entity/Q1309  11134943"]},"metadata":{},"output_type":"display_data"}],"source":["record_linkage = []\n","\n","eta.begin(len(wd_places), 'Finding existing places')\n","for i, wd_place in wd_places.iterrows():\n","\n","    # Only same kind (or undefined)\n","    selection = gv_places[pd.isna(gv_places['kind']) | pd.isna(wd_place['kind']) | (gv_places['kind'] == wd_place['kind'])]\n","\n","    # Only take those around 5 (more or less, so max: diag of 10km squared: max ~14km) km around (since they already have the same kind, it makes sense)\n","    selection = selection[pd.isna(wd_place['lat']) | pd.isna(selection['lat'])  | (wd_place['lat'] - 0.05 < selection['lat'])]\n","    selection = selection[pd.isna(wd_place['lat']) | pd.isna(selection['lat'])  | (selection['lat'] < wd_place['lat'] + 0.05)]\n","    selection = selection[pd.isna(wd_place['lng']) | pd.isna(selection['lng'])  | (wd_place['lng'] - 0.05 < selection['lng'])]\n","    selection = selection[pd.isna(wd_place['lng']) | pd.isna(selection['lng'])  | (selection['lng'] < wd_place['lng'] + 0.05)]\n","\n","    # Shorten selection\n","    selection = selection[['pk_geoplace', 'name', 'uri']].drop_duplicates()\n","\n","    # Only those with the same name\n","    selection = selection[[pd.notna(wd_place['name']) and pd.notna(row['name']) and wd_place['name'] == row['name'] for _, row in selection.iterrows()]]\n","\n","    # To avoid multipling duplicates, we only take the first who matches\n","    if len(selection) > 0:\n","        record_linkage.append({'wd_uri': wd_place['uri'], 'pk_gv': selection.iloc[0]['pk_geoplace']})\n","\n","    eta.iter()\n","eta.end()\n","\n","record_linkage = pd.DataFrame(data=record_linkage)\n","record_linkage.drop_duplicates(inplace=True)\n","u.write_df(record_linkage, './places-rl.csv')\n","\n","a.infos(record_linkage)\n","\n","# 151m"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["record_linkage = u.read_df('./places-rl.csv')\n","record_linkage['pk_gv'] = record_linkage['pk_gv'].astype(int)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape:  (5959, 8) - extract:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>definition</th>\n","      <th>lat</th>\n","      <th>lng</th>\n","      <th>uri</th>\n","      <th>place_classLabel</th>\n","      <th>kind</th>\n","      <th>pk_gv</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bern</td>\n","      <td>city in Switzerland, capital of the canton of ...</td>\n","      <td>46.94798</td>\n","      <td>7.44743</td>\n","      <td>http://www.wikidata.org/entity/Q70</td>\n","      <td>city</td>\n","      <td>Settlement</td>\n","      <td>80681</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bern</td>\n","      <td>city in Switzerland, capital of the canton of ...</td>\n","      <td>46.94798</td>\n","      <td>7.44743</td>\n","      <td>http://www.wikidata.org/entity/Q70</td>\n","      <td>capital city</td>\n","      <td>Settlement</td>\n","      <td>80681</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bern</td>\n","      <td>city in Switzerland, capital of the canton of ...</td>\n","      <td>46.94798</td>\n","      <td>7.44743</td>\n","      <td>http://www.wikidata.org/entity/Q70</td>\n","      <td>administrative division</td>\n","      <td>Settlement</td>\n","      <td>80681</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Bern</td>\n","      <td>city in Switzerland, capital of the canton of ...</td>\n","      <td>46.94798</td>\n","      <td>7.44743</td>\n","      <td>http://www.wikidata.org/entity/Q70</td>\n","      <td>municipality of Switzerland</td>\n","      <td>Settlement</td>\n","      <td>80681</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Bern</td>\n","      <td>city in Switzerland, capital of the canton of ...</td>\n","      <td>46.94798</td>\n","      <td>7.44743</td>\n","      <td>http://www.wikidata.org/entity/Q70</td>\n","      <td>federal city</td>\n","      <td>Settlement</td>\n","      <td>80681</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   name                                         definition       lat      lng  \\\n","0  Bern  city in Switzerland, capital of the canton of ...  46.94798  7.44743   \n","1  Bern  city in Switzerland, capital of the canton of ...  46.94798  7.44743   \n","2  Bern  city in Switzerland, capital of the canton of ...  46.94798  7.44743   \n","3  Bern  city in Switzerland, capital of the canton of ...  46.94798  7.44743   \n","4  Bern  city in Switzerland, capital of the canton of ...  46.94798  7.44743   \n","\n","                                  uri             place_classLabel  \\\n","0  http://www.wikidata.org/entity/Q70                         city   \n","1  http://www.wikidata.org/entity/Q70                 capital city   \n","2  http://www.wikidata.org/entity/Q70      administrative division   \n","3  http://www.wikidata.org/entity/Q70  municipality of Switzerland   \n","4  http://www.wikidata.org/entity/Q70                 federal city   \n","\n","         kind  pk_gv  \n","0  Settlement  80681  \n","1  Settlement  80681  \n","2  Settlement  80681  \n","3  Settlement  80681  \n","4  Settlement  80681  "]},"metadata":{},"output_type":"display_data"}],"source":["data = wd_places.merge(record_linkage, left_on='uri', right_on='wd_uri', how='left').drop(columns=['wd_uri'])\n","data['pk_gv'] = data['pk_gv'].astype(pd.Int64Dtype())\n","\n","a.infos(data)"]},{"cell_type":"markdown","metadata":{},"source":["# Find existing Geographical place and add them to the project"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Adding entities...\n","[DB] Creating info_proj_rel of 914 entities with project <153> ... Done in [00h00m01s]\n","Creating Names...\n","[DB] Creating 906 resources of class [365] ... Done in [00h00m00s]\n","[DB] Creating info_proj_rel of 906 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 906 appellations ... Done in [00h00m00s]\n","[DB] Creating 906 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 906 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 906 statements ... Updating metadata ... Done in [00h00m00s]\n","[DB] Creating info_proj_rel of 906 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 906 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 906 entities with project <153> ... Done in [00h00m00s]\n","Creating Definitions...\n","[DB] Creating 910 resources of class [899] ... Done in [00h00m00s]\n","[DB] Creating info_proj_rel of 910 entities with project <153> ... Done in [00h00m01s]\n","[DB] Creating 910 appellations ... Done in [00h00m00s]\n","[DB] Creating 910 statements ... Updating metadata ... Done in [00h00m00s]\n","[DB] Creating info_proj_rel of 910 entities with project <153> ... Done in [00h00m01s]\n","[DB] Creating 910 statements ... Updating metadata ... Done in [00h00m00s]\n","[DB] Creating info_proj_rel of 910 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 910 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 910 entities with project <153> ... Done in [00h00m00s]\n","Creating Presence...\n","[DB] Creating 912 places ... Done in [00h01m00s]\n","[DB] Creating 912 resources of class [84] ... Done in [00h00m00s]\n","[DB] Creating info_proj_rel of 912 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 912 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 912 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 912 statements ... Updating metadata ... Done in [00h00m00s]\n","[DB] Creating info_proj_rel of 912 entities with project <153> ... Done in [00h00m00s]\n","Creating URIs...\n","[DB] Creating 910 resources of class [967] ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 910 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 910 appellations ... Done in [00h00m00s]\n","[DB] Creating 910 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 910 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 910 statements ... Updating metadata ... Done in [00h00m00s]\n","[DB] Creating info_proj_rel of 910 entities with project <153> ... Done in [00h00m01s]\n"]}],"source":["existing_places = data[pd.notna(data['pk_gv'])].copy()\n","existing_places.drop(columns=['place_classLabel'], inplace=True)\n","existing_places.drop_duplicates(inplace=True)\n","\n","print('Adding entities...')\n","db.info_proj_rels.create(existing_places['pk_gv'])\n","\n","# Names\n","print('Creating Names...')\n","selection = existing_places[['pk_gv', 'name']].drop_duplicates().dropna()\n","db.shortcuts.add_entity_names(selection['pk_gv'], selection['name'], pks.languages.english)\n","\n","# Definition\n","print('Creating Definitions...')\n","selection = existing_places[['pk_gv', 'definition']].drop_duplicates().dropna()\n","db.shortcuts.add_definitions(selection['pk_gv'], selection['definition'], pks.languages.english)\n","\n","# Presence\n","print('Creating Presence...')\n","selection = existing_places[['pk_gv', 'lat', 'lng']].drop_duplicates().dropna()\n","points = [(float(row['lat']), float(row['lng'])) for _, row in selection.iterrows()]\n","db.shortcuts.add_geo_coordinates(selection['pk_gv'], points)\n","\n","# URI\n","print('Creating URIs...')\n","selection = existing_places[['pk_gv', 'uri']].drop_duplicates().dropna()\n","db.shortcuts.add_uris(selection['pk_gv'], selection['uri'])"]},{"cell_type":"markdown","metadata":{},"source":["# Create Geographical places"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Creating entities...\n","[DB] Creating 2409 resources of class [363] ... Done in [00h00m00s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m00s]\n","Creating Names...\n","[DB] Creating 2409 resources of class [365] ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 2409 appellations ... Done in [00h00m01s]\n","[DB] Creating 2409 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 2409 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m01s]\n","[DB] Creating 2409 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m00s]\n","Creating Definitions...\n","[DB] Creating 2409 resources of class [899] ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 2409 appellations ... Done in [00h00m02s]\n","[DB] Creating 2409 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 2409 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m01s]\n","[DB] Creating 2409 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m01s]\n","Creating Presence...\n","[DB] Creating 2431 places ... Done in [00h02m46s]\n","[DB] Creating 2431 resources of class [84] ... Done in [00h00m00s]\n","[DB] Creating info_proj_rel of 2431 entities with project <153> ... Done in [00h00m01s]\n","[DB] Creating 2431 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2431 entities with project <153> ... Done in [00h00m00s]\n","[DB] Creating 2431 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2431 entities with project <153> ... Done in [00h00m01s]\n","Creating URIs...\n","[DB] Creating 2409 resources of class [967] ... Done in [00h00m00s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m01s]\n","[DB] Creating 2409 appellations ... Done in [00h00m01s]\n","[DB] Creating 2409 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m01s]\n","[DB] Creating 2409 statements ... Updating metadata ... Done in [00h00m01s]\n","[DB] Creating info_proj_rel of 2409 entities with project <153> ... Done in [00h00m00s]\n"]}],"source":["new_places = data[pd.isna(data['pk_gv'])].copy()\n","new_places.drop(columns=['pk_gv'], inplace=True)\n","\n","# Entity\n","print('Creating entities...')\n","selection = new_places[['uri']].drop_duplicates().copy()\n","selection['pk_gv'] = db.resources.create(pks.classes.geoPlace, len(selection))\n","new_places = new_places.merge(selection, how='left')\n","\n","# Names\n","print('Creating Names...')\n","selection = new_places[['pk_gv', 'name']].drop_duplicates().dropna()\n","db.shortcuts.add_entity_names(selection['pk_gv'], selection['name'], pks.languages.english)\n","\n","# Definition\n","print('Creating Definitions...')\n","selection = new_places[['pk_gv', 'definition']].drop_duplicates().dropna()\n","db.shortcuts.add_definitions(selection['pk_gv'], selection['definition'], pks.languages.english)\n","\n","# Presence\n","print('Creating Presence...')\n","selection = new_places[['pk_gv', 'lat', 'lng']].drop_duplicates().dropna()\n","points = [(float(row['lat']), float(row['lng'])) for _, row in selection.iterrows()]\n","db.shortcuts.add_geo_coordinates(selection['pk_gv'], points)\n","\n","# URI\n","print('Creating URIs...')\n","selection = new_places[['pk_gv', 'uri']].drop_duplicates().dropna()\n","db.shortcuts.add_uris(selection['pk_gv'], selection['uri'])"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["places = pd.concat([existing_places, new_places])"]},{"cell_type":"markdown","metadata":{},"source":["# Link person to their Birth and Death"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape:  (4074976, 3) - extract:\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pk_birth</th>\n","      <th>pk_death</th>\n","      <th>pk_geoplace</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>68429</td>\n","      <td>7777816</td>\n","      <td>80974</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>68429</td>\n","      <td>7777816</td>\n","      <td>80974</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>68429</td>\n","      <td>7777816</td>\n","      <td>80974</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>68429</td>\n","      <td>7777816</td>\n","      <td>80974</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>68429</td>\n","      <td>7777816</td>\n","      <td>80974</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   pk_birth  pk_death  pk_geoplace\n","0     68429   7777816        80974\n","1     68429   7777816        80974\n","2     68429   7777816        80974\n","3     68429   7777816        80974\n","4     68429   7777816        80974"]},"metadata":{},"output_type":"display_data"}],"source":["# First: get the hld_id <=> place table\n","\n","births = births[['hls_id', 'uri_wikidata_place']].rename(columns={'uri_wikidata_place':'uri'})\n","births = births.merge(places, how='left', on='uri')\n","births = births[['hls_id', 'pk_gv']].rename(columns={'pk_gv':'pk_geoplace'})\n","\n","deaths = deaths[['hls_id', 'uri_wikidata_place']].rename(columns={'uri_wikidata_place':'uri'})\n","deaths = deaths.merge(places, how='left', on='uri')\n","deaths = deaths[['hls_id', 'pk_gv']].rename(columns={'pk_gv':'pk_geoplace'})\n","\n","\n","# Then: Find the pk_person with this hls id\n","\n","persons = db.query(f\"\"\"\n","    select \n","        r0.pk_entity as pk_person,\n","        a3.string as uri,\n","        s3.fk_subject_info as pk_birth,\n","        s4.fk_subject_info as pk_death\n","    from information.resource r0\n","    inner join projects.info_proj_rel ipr0 on ipr0.fk_entity = r0.pk_entity and ipr0.fk_project = {pk_project} and ipr0.is_in_project = true\n","    inner join information.statement s1 on s1.fk_subject_info = r0.pk_entity and s1.fk_property = {pks.properties.entity_sameAsExternalIdentifier_identifier}\n","    inner join information.statement s2 on s2.fk_subject_info = s1.fk_object_info and s2.fk_property = {pks.properties.appe_hasValue_string}\n","    inner join information.appellation a3 on a3.pk_entity = s2.fk_object_info\n","    -- birth\n","    left join information.statement s3 on s3.fk_object_info = r0.pk_entity and s3.fk_property = {pks.properties.birth_broughtIntoLife_person}\n","    -- death\n","    left join information.statement s4 on s4.fk_object_info = r0.pk_entity and s4.fk_property = {pks.properties.death_wasDeathOf_person}\n","    where r0.fk_class = {pks.classes.person}\n","\"\"\")\n","\n","persons = persons[persons['uri'].str.contains('https://hls')]\n","persons['hls_id'] = persons['uri'].str.replace('https://hls-dhs-dss.ch/articles/', '')\n","persons['hls_id'] = persons['hls_id'].str.replace('https://hls-dhs-dss.ch/de/articles/009053/2015-11-18/', '009053')\n","persons['hls_id'] = persons['hls_id'].astype(int)\n","persons['pk_birth'] = persons['pk_birth'].astype(pd.Int64Dtype())\n","persons['pk_death'] = persons['pk_death'].astype(pd.Int64Dtype())\n","persons.drop(columns=['uri'], inplace=True)\n","\n","persons = persons.merge(births, how='left').rename(columns={'pk_geo_place':'pk_geoplace_birth'})\n","persons = persons.merge(deaths, how='left').rename(columns={'pk_geo_place':'pk_geoplace_death'})\n","\n","persons.drop(columns=['pk_person', 'hls_id'], inplace=True)\n","\n","a.infos(persons)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[DB] Creating 13469 statements ... Updating metadata ... Done in [00h00m06s]\n","[DB] Creating info_proj_rel of 13469 entities with project <153> ... Done in [00h00m02s]\n","[DB] Creating 13347 statements ... Updating metadata ... Done in [00h00m06s]\n","[DB] Creating info_proj_rel of 13347 entities with project <153> ... Done in [00h00m03s]\n"]}],"source":["# Link births to their place\n","selection = persons[['pk_birth', 'pk_geoplace']].drop_duplicates().dropna()\n","db.statements.create(selection['pk_birth'], pks.properties.period_tookPlaceOnOrWithin_phyThing, selection['pk_geoplace'])\n","\n","# Link deaths to their place\n","selection = persons[['pk_death', 'pk_geoplace']].drop_duplicates().dropna()\n","db.statements.create(selection['pk_death'], pks.properties.period_tookPlaceOnOrWithin_phyThing, selection['pk_geoplace'])"]},{"cell_type":"markdown","metadata":{},"source":["---"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
